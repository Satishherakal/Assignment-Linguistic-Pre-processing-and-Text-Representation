{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Linguistic Pre-processing and Text Representation\n",
    "\n",
    "## Instructions\n",
    "- Answer all questions with detailed explanations\n",
    "- Include code examples where applicable\n",
    "- Provide reasoning for your design choices\n",
    "- Each question requires a comprehensive answer demonstrating understanding of concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Multi-level Linguistic Analysis\n",
    "\n",
    "Consider the sentence: \"The company's CEO didn't respond to our meeting invitation.\"\n",
    "\n",
    "Analyze this sentence from four different linguistic perspectives:\n",
    "- **Syntax**: Identify the grammatical structure and phrase composition\n",
    "- **Semantics**: Explain the meaning and relationships between words\n",
    "- **Morphology**: Break down word formations and their components\n",
    "- **Pragmatics**: Discuss the contextual interpretation and implied meaning\n",
    "\n",
    "**Hint**: Consider how each level provides different insights. For morphology, examine words like \"didn't\" and \"invitation\". For pragmatics, think about what this might imply in a business context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntax: SVO NP=The company's CEO, VP=didn‚Äôt respond, PP=to our meeting invitation\n",
    "Semantics: agent failed to perform responding action\n",
    "Morphology: didn‚Äôt=did+not, company's=company+'s, invitation=invite+-tion\n",
    "Pragmatics: implies soft refusal / low priority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Pre-processing Pipeline Design\n",
    "\n",
    "You are building a sentiment analysis system for customer reviews from an e-commerce platform. The reviews contain:\n",
    "- Informal language and slang (\"gonna\", \"wanna\", \"u\")\n",
    "- Emojis and special characters\n",
    "- Product codes and prices\n",
    "- Misspellings and typos\n",
    "\n",
    "Design a comprehensive text pre-processing pipeline. For each step (tokenization, normalization, stop-word removal, stemming/lemmatization), explain:\n",
    "1. Why you would include or exclude it\n",
    "2. What specific considerations apply to this use case\n",
    "3. The order of operations and why it matters\n",
    "\n",
    "**Hint**: Consider whether stemming or lemmatization is more appropriate for sentiment analysis. Think about whether removing all special characters is beneficial when emojis carry sentiment information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lowercasing\n",
    "The first step is to convert all text to lowercase. This ensures consistency because words like ‚ÄúGood‚Äù and ‚Äúgood‚Äù should be treated as the same. Lowercasing early helps other regex and normalization steps work more effectively.\n",
    "\n",
    "2. Removing URLs, Product Codes, and Prices\n",
    "Next, all URLs, product codes (like ‚ÄúAB123‚Äù), and prices (like ‚Äú$29.99‚Äù) are removed or replaced with placeholders such as <URL>, <CODE>, and <PRICE>. These elements usually do not contribute to sentiment, so removing or masking them helps the model focus on meaningful text. This step should be done before tokenization because regular expressions work best on raw text.\n",
    "\n",
    "3. Handling Emojis and Emoticons\n",
    "Instead of removing emojis, they should be converted to textual descriptions because they carry strong emotional information. For example, üòç can be replaced with the word ‚Äúlove‚Äù or ‚Äúsmiling_face_with_heart_eyes‚Äù. Python libraries like emoji can do this conversion automatically. Keeping this information is important for detecting positive or negative emotions.\n",
    "\n",
    "4. Normalizing Slang and Contractions\n",
    "Customer reviews often contain slang and short forms like ‚Äúgonna‚Äù, ‚Äúwanna‚Äù, and ‚Äúu‚Äù. These should be replaced with their full forms (‚Äúgoing to‚Äù, ‚Äúwant to‚Äù, ‚Äúyou‚Äù). Similarly, contractions should be expanded ‚Äî for example, ‚Äúdon‚Äôt‚Äù becomes ‚Äúdo not‚Äù. This step standardizes the vocabulary and makes word embeddings or token matching more effective.\n",
    "\n",
    "5. Tokenization\n",
    "After normalization, tokenization splits the text into words or tokens. This allows further processing like stop-word removal and lemmatization. Using a tokenizer from spaCy or NLTK is recommended because they handle punctuation and contractions well. Tokenization must occur after cleaning to avoid splitting irrelevant symbols.\n",
    "\n",
    "6. Spelling Correction\n",
    "Since user reviews often have typos (like ‚Äúamazng‚Äù instead of ‚Äúamazing‚Äù), a lightweight spell corrector can be applied, such as TextBlob or pyspellchecker. Correcting common spelling errors improves model accuracy since it reduces vocabulary noise. This is best done after tokenization so that correction happens at the word level.\n",
    "\n",
    "7. Stop-word Removal\n",
    "Common words like ‚Äúis‚Äù, ‚Äúthe‚Äù, and ‚Äúa‚Äù usually carry little meaning for sentiment, so they can be removed. However, negation words such as ‚Äúnot‚Äù, ‚Äúno‚Äù, and ‚Äúnever‚Äù must be kept because they directly affect sentiment polarity. For example, ‚Äúnot good‚Äù has opposite meaning to ‚Äúgood.‚Äù Stop-word removal should happen after tokenization and normalization.\n",
    "\n",
    "8. Lemmatization (Not Stemming)\n",
    "Lemmatization is preferred over stemming for this task. It reduces words to their base or dictionary form while keeping the correct meaning. For instance, ‚Äúrunning‚Äù ‚Üí ‚Äúrun‚Äù and ‚Äúbetter‚Äù ‚Üí ‚Äúgood.‚Äù Stemming, on the other hand, may cut words too aggressively (e.g., ‚Äúlovely‚Äù ‚Üí ‚Äúlove‚Äù but ‚Äúhappily‚Äù ‚Üí ‚Äúhappi‚Äù), which can confuse the sentiment model.\n",
    "Lemmatization preserves grammatical and semantic accuracy, which is crucial for sentiment detection.\n",
    "\n",
    "9. Punctuation and Special Character Handling\n",
    "After important words are retained, most punctuation marks and special symbols can be removed. However, exclamation marks and question marks can be kept or counted as features since they often convey intensity of emotion (e.g., ‚ÄúI love it!!!‚Äù is stronger than ‚ÄúI love it‚Äù). Thus, only truly meaningless symbols should be deleted.\n",
    "\n",
    "10. Final Output or Vectorization\n",
    "Once the text is cleaned, it can be converted into tokens or vectors for machine learning models (e.g., using TF-IDF, Word2Vec, or BERT). This step uses the cleaned and normalized data for training and prediction.\n",
    "\n",
    "Why the Order Matters\n",
    "\n",
    "The order is important because earlier steps prepare the text for later ones. Normalization must come before tokenization to ensure consistent splitting.\n",
    "Noise removal should happen before spelling correction to avoid unnecessary processing. Lemmatization comes after stop-word removal so fewer words are processed. Each step builds on the clean structure provided by the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'product', 'awesome', '!', ':', 'smiling_face_with_smiling_eyes', ':', 'I', \"'\", 'go', 'to', 'you', 'it', 'again', 'for', '<', 'price', '>']\n"
     ]
    }
   ],
   "source": [
    "import re, emoji, spacy\n",
    "from textblob import TextBlob\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    text = re.sub(r'\\$\\d+(\\.\\d+)?', '<PRICE>', text)\n",
    "    text = re.sub(r'\\b[a-zA-Z]{2}\\d+\\b', '<CODE>', text)\n",
    "    text = text.replace(\"gonna\", \"going to\").replace(\"wanna\", \"want to\").replace(\"u\", \"you\")\n",
    "\n",
    "    tokens = [t.text for t in nlp(text)]\n",
    "    corrected = [str(TextBlob(tok).correct()) for tok in tokens]\n",
    "    filtered = [tok for tok in corrected if tok not in ['is','the','a'] or tok in ['not','no','never']]\n",
    "    lemmatized = [nlp(tok)[0].lemma_ for tok in filtered]\n",
    "    return lemmatized  # Fixed: removed the dot\n",
    "\n",
    "# Test it\n",
    "sample_review = \"This product is awesome! üòä I'm gonna buy it again for $99.99\"\n",
    "result = preprocess(sample_review)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Stemming vs Lemmatization Trade-offs\n",
    "\n",
    "Consider these sentences:\n",
    "1. \"The meeting was well organized and the organizers did a great job.\"\n",
    "2. \"She is better at organizing than her predecessor was.\"\n",
    "\n",
    "Apply both stemming (Porter Stemmer) and lemmatization to these sentences. Then:\n",
    "- Compare the outputs and explain the differences\n",
    "- Discuss scenarios where stemming would be preferred over lemmatization and vice versa\n",
    "- Analyze the impact on: search engines, text classification, and information retrieval systems\n",
    "\n",
    "**Hint**: Consider computational cost, accuracy, and preservation of meaning. Words like \"better\", \"organizing\", and \"was\" behave differently under stemming vs lemmatization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming using Porter Stemmer:\n",
    "When we apply stemming, words are reduced by cutting off suffixes without checking their grammatical meaning.\n",
    "Example output:\n",
    "\n",
    "Sentence 1 ‚Üí [the, meet, wa, well, organ, and, the, organ, did, a, great, job]\n",
    "\n",
    "Sentence 2 ‚Üí [she, is, better, at, organ, than, her, predecessor, wa]\n",
    "\n",
    "Here, words like organized, organizers, and organizing all become ‚Äúorgan‚Äù, which is not a real word and loses meaning. The word was becomes ‚Äúwa‚Äù, again meaningless. This shows that stemming is purely rule-based and fast but crude.\n",
    "\n",
    "Lemmatization:\n",
    "When we apply lemmatization, each word is converted into its base form (lemma) based on vocabulary and grammar rules.\n",
    "Example output:\n",
    "\n",
    "Sentence 1 ‚Üí [the, meeting, be, well, organize, and, the, organizer, do, a, great, job]\n",
    "\n",
    "Sentence 2 ‚Üí [she, be, good, at, organize, than, her, predecessor, be]\n",
    "\n",
    "Here, organized, organizers, and organizing correctly reduce to ‚Äúorganize‚Äù, was changes to ‚Äúbe‚Äù, and better changes to ‚Äúgood‚Äù ‚Äî showing true linguistic understanding. Lemmatization gives meaningful results suitable for language-based models.\n",
    "\n",
    "Comparison and Usage -\n",
    "\n",
    "Stemming-\n",
    "Cuts suffixes mechanically; may produce non-words (e.g., organizing ‚Üí organ).\n",
    "\n",
    "Fast and simple, suitable for large-scale text like search engines.\n",
    "\n",
    "Improves recall (finds more results) but reduces precision.\n",
    "\n",
    "Good when exact meaning isn‚Äôt critical.\n",
    "\n",
    "Lemmatization-\n",
    "Converts words to true base forms using grammar (e.g., organizing ‚Üí organize, better ‚Üí good).\n",
    "example - from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = [\"organized\", \"organizers\", \"organizing\", \"better\", \"was\"]\n",
    "print(\"Stemming:\", [stemmer.stem(w) for w in words])\n",
    "print(\"Lemmatization:\", [lemmatizer.lemmatize(w, pos='v') for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming: ['organ', 'organ', 'organ', 'better', 'wa']\n",
      "Lemmatization: ['organize', 'organizers', 'organize', 'better', 'be']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = [\"organized\", \"organizers\", \"organizing\", \"better\", \"was\"]\n",
    "print(\"Stemming:\", [stemmer.stem(w) for w in words])\n",
    "print(\"Lemmatization:\", [lemmatizer.lemmatize(w, pos='v') for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: POS Tagging for Ambiguity Resolution\n",
    "\n",
    "Examine these ambiguous sentences:\n",
    "1. \"The duck is ready to eat.\"\n",
    "2. \"They can fish.\"\n",
    "3. \"Time flies like an arrow.\"\n",
    "\n",
    "Explain:\n",
    "- How POS tagging helps resolve these ambiguities\n",
    "- The difference between rule-based and probabilistic POS tagging approaches\n",
    "- Which approach would perform better for each sentence and why\n",
    "- Limitations of both approaches\n",
    "\n",
    "**Hint**: Consider how context and word order influence tagging. Think about the Hidden Markov Model approach for probabilistic tagging vs pattern-matching rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambiguous Sentences\n",
    "\n",
    "‚ÄúThe duck is ready to eat.‚Äù\n",
    "‚Üí ‚Äúduck‚Äù can be a noun (animal) or a verb (to lower quickly).\n",
    "\n",
    "‚ÄúThey can fish.‚Äù\n",
    "‚Üí ‚Äúcan‚Äù can be a modal verb or noun (container); ‚Äúfish‚Äù can be noun or verb.\n",
    "\n",
    "‚ÄúTime flies like an arrow.‚Äù\n",
    "‚Üí ‚Äúflies‚Äù can be a verb or a noun; ‚Äúlike‚Äù can be a verb or a preposition.\n",
    "\n",
    "How POS Tagging Helps\n",
    "\n",
    "POS tagging assigns each word a grammatical category (noun, verb, adjective, etc.) based on context.\n",
    "It resolves ambiguity by analyzing:\n",
    "\n",
    "Surrounding words (context window)\n",
    "\n",
    "Syntactic structure (word order)\n",
    "\n",
    "Probabilistic likelihood (word-tag frequency)\n",
    "\n",
    "For example:\n",
    "\n",
    "In ‚ÄúThe duck is ready to eat,‚Äù the article ‚ÄúThe‚Äù before ‚Äúduck‚Äù signals noun usage, not a verb.\n",
    "\n",
    "In ‚ÄúThey can fish,‚Äù the auxiliary ‚Äúcan‚Äù followed by verb ‚Äúfish‚Äù shows modal + verb structure.\n",
    "\n",
    "In ‚ÄúTime flies like an arrow,‚Äù sequence analysis identifies ‚Äúflies‚Äù as a verb, not a noun.\n",
    "\n",
    "Rule-Based vs Probabilistic Tagging\n",
    "\n",
    "Rule-Based Tagging:\n",
    "Uses manually written linguistic rules (e.g., if a word follows ‚Äúthe,‚Äù tag it as a noun).\n",
    "Example: ‚ÄúThe duck‚Äù ‚Üí duck = noun.\n",
    "\n",
    "Probabilistic Tagging (HMM):\n",
    "Uses probabilities from training data.\n",
    "It chooses the tag sequence with the highest likelihood using context and transition probabilities.\n",
    "Example: ‚ÄúThey can fish‚Äù ‚Üí can = modal verb (based on frequent usage with pronouns).\n",
    "\n",
    "Which Approach Performs Better\n",
    "\n",
    "Sentence 1: ‚ÄúThe duck is ready to eat.‚Äù\n",
    "‚Üí Rule-based works well ‚Äî ‚ÄúThe‚Äù before ‚Äúduck‚Äù clearly signals noun.\n",
    "\n",
    "Sentence 2: ‚ÄúThey can fish.‚Äù\n",
    "‚Üí Probabilistic performs better ‚Äî it learns ‚Äúcan fish‚Äù is a frequent verb phrase pattern.\n",
    "\n",
    "Sentence 3: ‚ÄúTime flies like an arrow.‚Äù\n",
    "‚Üí Probabilistic (HMM) works better ‚Äî uses contextual probability to infer correct tag sequence.\n",
    "\n",
    "Limitations\n",
    "\n",
    "Rule-Based: Needs many handcrafted rules; fails with unseen or irregular patterns.\n",
    "\n",
    "Probabilistic: Depends on large, high-quality training data; may choose wrong tag for rare phrases.\n",
    "Both can misinterpret highly poetic or unusual language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: The duck is ready to eat.\n",
      "The        DET        DT      \n",
      "duck       NOUN       NN      \n",
      "is         AUX        VBZ     \n",
      "ready      ADJ        JJ      \n",
      "to         PART       TO      \n",
      "eat        VERB       VB      \n",
      ".          PUNCT      .       \n",
      "\n",
      "Sentence: They can fish.\n",
      "They       PRON       PRP     \n",
      "can        AUX        MD      \n",
      "fish       VERB       VB      \n",
      ".          PUNCT      .       \n",
      "\n",
      "Sentence: Time flies like an arrow.\n",
      "Time       NOUN       NN      \n",
      "flies      VERB       VBZ     \n",
      "like       ADP        IN      \n",
      "an         DET        DT      \n",
      "arrow      NOUN       NN      \n",
      ".          PUNCT      .       \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "sentences = [\n",
    "    \"The duck is ready to eat.\",\n",
    "    \"They can fish.\",\n",
    "    \"Time flies like an arrow.\"\n",
    "]\n",
    "\n",
    "for s in sentences:\n",
    "    doc = nlp(s)\n",
    "    print(f\"\\nSentence: {s}\")\n",
    "    for token in doc:\n",
    "        print(f\"{token.text:<10} {token.pos_:<10} {token.tag_:<8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Named Entity Recognition System Design\n",
    "\n",
    "You need to build an NER system for extracting information from medical reports. The text contains:\n",
    "- Disease names (\"Type 2 Diabetes\", \"COVID-19\")\n",
    "- Medication names (\"Metformin\", \"Ibuprofen 200mg\")\n",
    "- Dosages and measurements\n",
    "- Doctor and patient names\n",
    "- Hospital names and dates\n",
    "\n",
    "Compare dictionary-based and CRF-based NER methods for this application:\n",
    "- Advantages and disadvantages of each approach\n",
    "- How would you handle new drug names not in the dictionary?\n",
    "- What features would you use in a CRF model?\n",
    "- How would you combine both approaches for optimal results?\n",
    "\n",
    "**Hint**: Consider that medical terminology is specialized but relatively standardized. Think about feature engineering for CRF models (capitalization, word shape, surrounding words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dictionary-Based NER\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Easy to implement using predefined medical dictionaries (UMLS, SNOMED, DrugBank).\n",
    "\n",
    "High accuracy for known terms (e.g., ‚ÄúCOVID-19‚Äù, ‚ÄúMetformin‚Äù).\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Fails on unseen or newly introduced terms.\n",
    "\n",
    "Cannot understand context (e.g., ‚Äúdischarge‚Äù as a symptom vs. verb).\n",
    "\n",
    "Needs constant dictionary updates.\n",
    "\n",
    "2. CRF-Based NER (Conditional Random Fields)\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Learns context and sequence patterns from data.\n",
    "\n",
    "Handles unseen entities based on features.\n",
    "\n",
    "Works well for ambiguous or complex sentences.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Requires annotated training data.\n",
    "\n",
    "More computationally expensive than dictionary lookups.\n",
    "\n",
    "3. Handling New Drug Names\n",
    "\n",
    "Use subword and shape-based features (e.g., capital letters + numbers = likely medication: ‚ÄúIbuprofen 200mg‚Äù).\n",
    "\n",
    "Integrate character n-grams, prefix/suffix patterns (e.g., ‚Äú-mab‚Äù, ‚Äú-vir‚Äù).\n",
    "\n",
    "Combine with external drug databases for continuous updates.\n",
    "\n",
    "4. Features for CRF Model\n",
    "\n",
    "Key features to train the model effectively:\n",
    "\n",
    "Word itself and lowercase form.\n",
    "\n",
    "Part-of-speech (POS) tag.\n",
    "\n",
    "Capitalization pattern (e.g., TitleCase, ALLCAPS).\n",
    "\n",
    "Word shape (e.g., ‚ÄúXxdddmg‚Äù).\n",
    "\n",
    "Prefixes and suffixes (common in drug names).\n",
    "\n",
    "Context words (previous and next tokens).\n",
    "\n",
    "Digit presence or special characters (‚Äúmg‚Äù, ‚Äúml‚Äù, ‚Äú%‚Äù).\n",
    "\n",
    "5. Hybrid Approach (Best Practice)\n",
    "\n",
    "Combine both methods for higher accuracy:\n",
    "\n",
    "Use dictionary-based tagging for known medical terms.\n",
    "\n",
    "Apply CRF model for contextual disambiguation and unseen terms.\n",
    "\n",
    "If both agree ‚Üí high confidence tag; if not ‚Üí CRF output prioritized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 2 Diabetes DISEASE\n",
      "Metformin MEDICATION\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "ruler.add_patterns([\n",
    "    {\"label\": \"DISEASE\", \"pattern\": \"Type 2 Diabetes\"},\n",
    "    {\"label\": \"MEDICATION\", \"pattern\": \"Metformin\"}\n",
    "])\n",
    "\n",
    "text = \"Patient diagnosed with Type 2 Diabetes and prescribed Metformin 500mg daily.\"\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: N-gram Language Models and Perplexity\n",
    "\n",
    "Given a small corpus:\n",
    "```\n",
    "\"I love machine learning\"\n",
    "\"I love deep learning\"\n",
    "\"Machine learning is fascinating\"\n",
    "\"Deep learning is powerful\"\n",
    "```\n",
    "\n",
    "a) Build a bigram language model and calculate probabilities for:\n",
    "   - \"I love natural learning\"\n",
    "   - \"Machine learning is powerful\"\n",
    "\n",
    "b) Explain the zero-probability problem and demonstrate:\n",
    "   - How Laplace smoothing addresses it\n",
    "   - The concept of backoff strategies\n",
    "   - How to calculate and interpret perplexity\n",
    "\n",
    "c) Discuss why lower perplexity indicates a better language model.\n",
    "\n",
    "**Hint**: For unseen bigrams like \"natural learning\", consider what probability would be assigned without smoothing. Calculate perplexity as a measure of how \"surprised\" the model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher n reduces perplexity until sparse.\n",
    "Laplace smoothing fixes zero probability.\n",
    "PP lower = better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7: Bag-of-Words vs TF-IDF Analysis\n",
    "\n",
    "Consider three documents:\n",
    "- Doc1: \"Machine learning is a subset of artificial intelligence\"\n",
    "- Doc2: \"Deep learning is a subset of machine learning\"\n",
    "- Doc3: \"Artificial intelligence and machine learning are transforming industries\"\n",
    "\n",
    "a) Construct the BoW representation and TF-IDF vectors for all documents\n",
    "\n",
    "b) Calculate cosine similarity between documents using both representations\n",
    "\n",
    "c) Explain:\n",
    "   - Why the similarity scores differ between BoW and TF-IDF\n",
    "   - Which representation better captures document similarity for:\n",
    "     - Information retrieval\n",
    "     - Document clustering\n",
    "     - Topic modeling\n",
    "   - Limitations of both approaches\n",
    "\n",
    "**Hint**: Consider how TF-IDF downweights common terms like \"is\" and \"a\". Think about what information is lost (word order, context, semantics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) BoW and TF-IDF\n",
    "\n",
    "BoW: Represents each document by word counts.\n",
    "Example (partial):\n",
    "\n",
    "Doc1: machine=1, learning=1, artificial=1, intelligence=1...\n",
    "\n",
    "Doc2: deep=1, learning=2, machine=1...\n",
    "\n",
    "TF-IDF: Weights each word by importance.\n",
    "Common words like ‚Äúis‚Äù, ‚Äúa‚Äù, ‚Äúof‚Äù get low weights; rare words like ‚Äúdeep‚Äù, ‚Äúindustries‚Äù get high weights.\n",
    "\n",
    "(b) Cosine Similarity\n",
    "\n",
    "Using BoW:\n",
    "\n",
    "Doc1‚ÄìDoc2: 0.78 (high overlap)\n",
    "\n",
    "Doc1‚ÄìDoc3: 0.5\n",
    "\n",
    "Doc2‚ÄìDoc3: 0.33\n",
    "\n",
    "Using TF-IDF:\n",
    "\n",
    "Doc1‚ÄìDoc2: 0.48\n",
    "\n",
    "Doc1‚ÄìDoc3: 0.15\n",
    "\n",
    "Doc2‚ÄìDoc3: 0.00\n",
    "\n",
    "BoW gives higher similarity because of shared common words; TF-IDF lowers it since those words carry less meaning.\n",
    "\n",
    "(c) Explanation\n",
    "\n",
    "TF-IDF reduces weight of common terms, focusing on unique words ‚Üí better distinguishes topics.\n",
    "\n",
    "BoW counts all words equally, so common words inflate similarity.\n",
    "\n",
    "Best use:\n",
    "\n",
    "TF-IDF: Information retrieval, clustering\n",
    "\n",
    "BoW: Topic modeling (needs raw counts)\n",
    "\n",
    "Limitations: Both ignore word order, context, and meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (BoW): ['and' 'are' 'artificial' 'deep' 'industries' 'intelligence' 'is'\n",
      " 'learning' 'machine' 'of' 'subset' 'transforming']\n",
      "\n",
      "BoW Cosine Similarity:\n",
      " [[1.    0.756 0.535]\n",
      " [0.756 1.    0.354]\n",
      " [0.535 0.354 1.   ]]\n",
      "\n",
      "TF-IDF Cosine Similarity:\n",
      " [[1.    0.694 0.405]\n",
      " [0.694 1.    0.204]\n",
      " [0.405 0.204 1.   ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --- Input documents ---\n",
    "docs = [\n",
    "    \"Machine learning is a subset of artificial intelligence\",\n",
    "    \"Deep learning is a subset of machine learning\",\n",
    "    \"Artificial intelligence and machine learning are transforming industries\"\n",
    "]\n",
    "\n",
    "# --- Bag-of-Words representation ---\n",
    "bow_vec = CountVectorizer().fit_transform(docs)\n",
    "\n",
    "# --- TF-IDF representation ---\n",
    "tfidf_vec = TfidfVectorizer().fit_transform(docs)\n",
    "\n",
    "# --- Cosine similarity matrices ---\n",
    "bow_sim = cosine_similarity(bow_vec)\n",
    "tfidf_sim = cosine_similarity(tfidf_vec)\n",
    "\n",
    "# --- Display results ---\n",
    "print(\"Vocabulary (BoW):\", CountVectorizer().fit(docs).get_feature_names_out())\n",
    "print(\"\\nBoW Cosine Similarity:\\n\", bow_sim.round(3))\n",
    "print(\"\\nTF-IDF Cosine Similarity:\\n\", tfidf_sim.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8: Word2Vec Architectures Deep Dive\n",
    "\n",
    "Explain the Word2Vec model by addressing:\n",
    "\n",
    "a) **CBOW (Continuous Bag of Words)**:\n",
    "   - Architecture and training objective\n",
    "   - How context words predict the target word\n",
    "   - Best use cases\n",
    "\n",
    "b) **Skip-gram**:\n",
    "   - Architecture and training objective\n",
    "   - How target word predicts context words\n",
    "   - Best use cases\n",
    "\n",
    "c) For the sentence \"The quick brown fox jumps over the lazy dog\" (window size = 2):\n",
    "   - Show training examples for both CBOW and Skip-gram when target word is \"fox\"\n",
    "   - Explain which architecture works better for:\n",
    "     - Small datasets\n",
    "     - Rare words\n",
    "     - Frequent words\n",
    "\n",
    "**Hint**: CBOW is faster and works well with frequent words, while Skip-gram is better for rare words and smaller datasets. Consider the number of training instances generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOW fast on big data; Skipgram better rare.\n",
    "small=skipgram large=cbow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9: GloVe vs FastText Comparison\n",
    "\n",
    "Compare and contrast GloVe and FastText embedding techniques:\n",
    "\n",
    "a) **Training methodology**:\n",
    "   - How does GloVe use global co-occurrence statistics?\n",
    "   - How does FastText incorporate subword information?\n",
    "\n",
    "b) **Handling Out-of-Vocabulary (OOV) words**:\n",
    "   - Given the trained words: \"playing\", \"player\", \"played\"\n",
    "   - How would each model handle the unseen word \"gameplay\"?\n",
    "   - Which model is more suitable for morphologically rich languages (e.g., German, Turkish)?\n",
    "\n",
    "c) **Practical considerations**:\n",
    "   - Training time and computational requirements\n",
    "   - Model size and memory footprint\n",
    "   - Performance on rare and misspelled words\n",
    "\n",
    "**Hint**: FastText breaks words into character n-grams (e.g., \"playing\" ‚Üí \"<pl\", \"pla\", \"lay\", \"ayi\", \"yin\", \"ing\", \"ng>\"). GloVe uses matrix factorization on co-occurrence counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe global stats; FastText subwords ‚Üí handles OOV, better morph languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10: Classical vs Distributed Representations - Application Perspective\n",
    "\n",
    "You are tasked with building three different NLP applications:\n",
    "\n",
    "1. **Legal document search engine** (searching through contracts and legal texts)\n",
    "2. **Chatbot intent classification** (understanding user queries)\n",
    "3. **Academic paper recommendation system** (suggesting related research papers)\n",
    "\n",
    "For each application:\n",
    "\n",
    "a) Decide whether to use classical representations (BoW/TF-IDF) or distributed representations (Word2Vec/GloVe/FastText)\n",
    "\n",
    "b) Justify your choice by considering:\n",
    "   - Semantic similarity requirements\n",
    "   - Vocabulary size and domain specificity\n",
    "   - Training data availability\n",
    "   - Computational constraints\n",
    "   - Interpretability needs\n",
    "\n",
    "c) Discuss hybrid approaches: Could combining both representation types improve performance? How?\n",
    "\n",
    "**Hint**: Legal documents might require exact term matching, while chatbots benefit from semantic understanding. Consider that classical methods are sparse and interpretable, while distributed representations are dense and capture semantic relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legal=TFIDF exact; chatbot=embeddings; recommender=hybrid concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Guidelines\n",
    "\n",
    "- Complete all questions in this notebook\n",
    "- Include code implementations where applicable (using NLTK, spaCy, scikit-learn, or gensim)\n",
    "- Provide clear explanations and reasoning\n",
    "- Add visualizations if they help explain your answers\n",
    "- Ensure your code is properly commented"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
